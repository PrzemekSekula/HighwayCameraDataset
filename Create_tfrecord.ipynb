{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates tfrecord files for Google Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_FOLDER = './data/'\n",
    "labels = pd.read_csv(os.path.join(LABEL_FOLDER, 'data.csv'))\n",
    "labels = labels.sort_values('label')\n",
    "labels['code'] = labels.label.apply(lambda x: x.split('_')[0])\n",
    "prev_name = ''\n",
    "prev_value = 1\n",
    "for idx, row in labels.iterrows():\n",
    "    if row.code == prev_name:\n",
    "        prev_value += 1\n",
    "    else:\n",
    "        prev_value = 1\n",
    "        prev_name = row.code\n",
    "    code = '{}_{}'.format(prev_name, str(prev_value).zfill(2))\n",
    "    labels.at[idx, 'code'] = code\n",
    "#labels = labels.set_index('code')\n",
    "labels = labels.sort_index()\n",
    "labels.fillna(0, inplace=True)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_TRAIN = './tfrecord/train_{}.record'\n",
    "OUTPUT_TEST = './tfrecord/test_{}.record'\n",
    "\n",
    "TEST_IDX = 0 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_first_frame(df, fps):\n",
    "    first_time = df.TimeStamp.astype(int).min() / 1e9\n",
    "    if first_time > 0:\n",
    "        first_frame = np.round(first_time * fps)\n",
    "        #print ('First frame = {}'.format(first_frame))\n",
    "        tmp = df.groupby('TimeStamp').size().sort_index().reset_index().drop(0, axis=1)\n",
    "        tmp['frame'] = np.arange(len(tmp)) + first_frame\n",
    "        df = df.drop('frame', axis=1).merge(tmp, on='TimeStamp')\n",
    "    return df\n",
    "\n",
    "def change_values(df):\n",
    "    \"\"\"\n",
    "    Put everything that you want to change in data here.\n",
    "    \"\"\"\n",
    "    df.type.replace(to_replace = 'motorcycle', vlaue='vehicle', inplace=True)\n",
    "    return df\n",
    "\n",
    "def read_data(idx):\n",
    "    df = pd.read_excel(os.path.join(LABEL_FOLDER, labels.at[idx, 'label']))\n",
    "    df.TimeStamp = pd.to_timedelta(df.TimeStamp)\n",
    "    tmp = df.groupby('TimeStamp').size().sort_index().reset_index().drop(0, axis=1)\n",
    "    tmp['frame'] = np.arange(len(tmp)) - labels.at[idx, 'shift']\n",
    "    df = df.merge(tmp, on='TimeStamp')\n",
    "    \n",
    "    cap = cv2.VideoCapture(labels.loc[idx, 'video']) \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    df = set_first_frame(df, fps)\n",
    "    for col in ['x', 'y', 'frame']:\n",
    "        df[col] = df[col].astype(int)\n",
    "    return df, cap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: #Automatic\n",
    "    df_classes = df['type'].value_counts().to_frame()\n",
    "    df_classes.insert(0, 'class_id', range(1, 1 + len(df_classes)))\n",
    "else: # Manual\n",
    "    classes_dic = {\n",
    "        1 : 'vehicle',\n",
    "        2 : 'truck',\n",
    "        -1 : 'delete'\n",
    "    }\n",
    "    df_classes = pd.DataFrame(list(classes_dic.items()),columns = ['class_id','class_name']).set_index('class_name')\n",
    "df_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img, rows):\n",
    "    ### Plot rectangles filled with zeros\n",
    "    tmp = rows[rows.type == 'delete']\n",
    "    if len(tmp) > 0:\n",
    "        for idx, row in tmp.iterrows():\n",
    "            cv2.rectangle(img, (row.x, row.y), (row.x + row.width, row.y + row.height), (0, 0, 0), -1)\n",
    "    return img\n",
    "\n",
    "if True: ### Let's test it\n",
    "    idx = labels[labels.code == 'Amir_01'].index[0]\n",
    "    test_df, test_cap = read_data(idx)\n",
    "    frameno = test_df.frame.min()\n",
    "    test_cap.set(cv2.CAP_PROP_POS_FRAMES, frameno)\n",
    "    ret, test_img = test_cap.read()\n",
    "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(test_img)\n",
    "    plt.show()\n",
    "    test_img = process_image(test_img, test_df[test_df.frame == frameno])\n",
    "    plt.imshow(test_img)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(filename, img, frameno, df, debug=False):\n",
    "    \n",
    "    rows = df[df.frame == frameno]\n",
    "    img = process_image(img, rows)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    \n",
    "    xmins = list(rows['x'] / width)\n",
    "    xmaxs = list((rows['x'] + rows['width']) / width)\n",
    "    ymins = list(rows['y'] / height)\n",
    "    ymaxs = list((rows['y'] + rows['height']) / height)\n",
    "\n",
    "    classes_text = list(rows['type'])\n",
    "    classes = list(df_classes.loc[classes_text, 'class_id'])\n",
    "    \n",
    "    #with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "    #    encoded_image_data = fid.read()\n",
    "    is_success, im_buf_arr = cv2.imencode(\".jpg\", img)\n",
    "    encoded_image_data = im_buf_arr.tobytes()\n",
    "\n",
    "    \n",
    "    # Change strings into bytes\n",
    "    image_format = filename.split('.')[-1].encode('utf-8')\n",
    "    filename = filename.encode('utf-8')\n",
    "    classes_text = [x.encode('utf-8') for x in classes_text]\n",
    "\n",
    "    \n",
    "    if debug: #For debugging\n",
    "        print ('W, H:', width, height)\n",
    "        print ('xmins:', xmins)\n",
    "        print ('xmaxs:', xmaxs)\n",
    "        print ('ymins:', ymins)\n",
    "        print ('ymaxs:', ymaxs)\n",
    "        print ('classes_text:', classes_text)\n",
    "        print ('classes:', classes)\n",
    "        print ('Len of encoded data:', len(encoded_image_data))\n",
    "        print ('Image format:', image_format)\n",
    "        \n",
    "    tf_label_and_data = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    \n",
    "    return tf_label_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, test_cap = read_data(TEST_IDX)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: ### Let's test it\n",
    "    test_filename = labels.loc[TEST_IDX, 'video']\n",
    "    frameno = test_df.frame.min()\n",
    "    test_cap.set(cv2.CAP_PROP_POS_FRAMES, frameno)\n",
    "    ret, test_img = test_cap.read()\n",
    "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "    tld = create_tf_example(test_filename, test_img, frameno, test_df, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_codes = ['Amir_01', 'Qinglian_01', 'Binya_01']\n",
    "labels_test = labels[labels.code.isin(test_codes)].copy().reset_index()\n",
    "labels_train = labels[~labels.code.isin(test_codes)].copy().reset_index()\n",
    "\n",
    "print ('Labels test has {} datasets: {}'.format(len(labels_test), labels_test.code.unique()))\n",
    "print ('Labels train has {} datasets: {}'.format(len(labels_train), labels_train.code.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tf_record(labels, idx, output_path):\n",
    "    t = time()\n",
    "\n",
    "    df, cap = read_data(idx)    \n",
    "    output_path = output_path.format(str(idx).zfill(2))\n",
    "    \n",
    "    filename = labels.loc[TEST_IDX, 'video']\n",
    "\n",
    "    writer = tf.compat.v1.python_io.TFRecordWriter(output_path)\n",
    "    \n",
    "    i = 0\n",
    "    frameno, frameno_max = df.frame.min(), df.frame.max()\n",
    "    nr_frames = frameno_max - frameno\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frameno)\n",
    "    while frameno <= frameno_max:\n",
    "        if i%20 == 0:\n",
    "            sys.stdout.write('{:.1f}% ({}/{}) images processed in {:.1f} seconds           \\r'\n",
    "                            .format(100 * i / nr_frames, i, nr_frames, time() - t))        \n",
    "        i += 1    \n",
    "        ret, img = test_cap.read()\n",
    "        \n",
    "        if frameno not in df.frame:\n",
    "            frameno += 1\n",
    "            print ('Warning: No vehicles for frame: {}'.format(frameno))\n",
    "            continue\n",
    "        \n",
    "        tf_example = create_tf_example(filename, img, frameno, test_df, debug=False)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "        frameno += 1\n",
    "        \n",
    "    writer.close()\n",
    "    \n",
    "    print('{}/{} ({}) done. {} images has been processed in {:.1f} seconds and written to {}                              '\n",
    "          .format(\n",
    "              idx+1, len(labels), labels.at[idx, 'code'],\n",
    "              nr_frames, time() - t, output_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in labels_train.index:\n",
    "    generate_tf_record(labels_train, idx, OUTPUT_TRAIN)\n",
    "for idx in labels_test.index:\n",
    "    generate_tf_record(labels_test, idx, OUTPUT_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_dic(height, width, img_format, xmin, xmax, ymin, ymax, label, text, image = None):\n",
    "    dic = {}\n",
    "    dic['height'] = height\n",
    "    dic['width'] = width\n",
    "    dic['format'] = img_format\n",
    "    dic['xmin'] = xmin\n",
    "    dic['xmax'] = xmax\n",
    "    dic['ymin'] = ymin\n",
    "    dic['ymax'] = ymax\n",
    "    dic['label'] = label\n",
    "    dic['text'] = text\n",
    "    if image is not None:\n",
    "        dic['image'] = image\n",
    "    return dic\n",
    "\n",
    "def load_file_data(tfrecord_path, load_images = True):\n",
    "    i = 0\n",
    "    features = {'image/filename' : tf.FixedLenFeature([], tf.string),\n",
    "                'image/height' : tf.FixedLenFeature([], tf.int64),\n",
    "                'image/width' : tf.FixedLenFeature([], tf.int64),\n",
    "                'image/format' : tf.FixedLenFeature([], tf.string),\n",
    "                'image/encoded' : tf.FixedLenFeature([], tf.string),\n",
    "                'image/object/bbox/xmin': tf.VarLenFeature(dtype=tf.float32),\n",
    "                'image/object/bbox/xmax': tf.VarLenFeature(dtype=tf.float32),\n",
    "                'image/object/bbox/ymin': tf.VarLenFeature(dtype=tf.float32),\n",
    "                'image/object/bbox/ymax': tf.VarLenFeature(dtype=tf.float32),\n",
    "                'image/object/class/label': tf.VarLenFeature(dtype=tf.int64),\n",
    "                'image/object/class/text': tf.VarLenFeature(dtype=tf.string),                     \n",
    "               }\n",
    "\n",
    "    loaded_files = {}\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        for s_example in tf.python_io.tf_record_iterator(tfrecord_path):\n",
    "            example = tf.parse_single_example(s_example, features=features)\n",
    "            (filename, height, width, img_format, \n",
    "             xmin, xmax, ymin, ymax, label, text) = sess.run([\n",
    "                example['image/filename'],\n",
    "                example['image/height'],\n",
    "                example['image/width'],\n",
    "                example['image/format'],\n",
    "                example['image/object/bbox/xmin'],\n",
    "                example['image/object/bbox/xmax'],\n",
    "                example['image/object/bbox/ymin'],\n",
    "                example['image/object/bbox/ymax'],\n",
    "                example['image/object/class/label'],\n",
    "                example['image/object/class/text'],\n",
    "            ])\n",
    "\n",
    "\n",
    "            filename = filename.decode(\"utf-8\") \n",
    "            img_format = img_format.decode(\"utf-8\") \n",
    "\n",
    "            text = [x.decode('utf-8') for x in text.values]\n",
    "            label = label.values\n",
    "            xmin = xmin.values\n",
    "            xmax = xmax.values\n",
    "            ymin = ymin.values\n",
    "            ymax = ymax.values\n",
    "\n",
    "            if load_images:\n",
    "                if img_format == 'png':\n",
    "                    image = tf.image.decode_png(example['image/encoded'])\n",
    "                elif img_format == 'jpg' or img_format == 'jpeg':\n",
    "                    image = tf.image.decode_jpeg(example['image/encoded'])\n",
    "                else:\n",
    "                    raise ('Unknown Image Format:' + img_format)\n",
    "\n",
    "                image = sess.run(image)\n",
    "                \n",
    "                loaded_files[filename] = create_file_dic(height, width, img_format, \n",
    "                    xmin, xmax, ymin, ymax,\n",
    "                    label, text, image)\n",
    "            else:\n",
    "                loaded_files[filename] = create_file_dic(height, width, img_format, \n",
    "                    xmin, xmax, ymin, ymax,\n",
    "                    label, text, image=None)\n",
    "\n",
    "            i += 1\n",
    "            sys.stdout.write('{} files processed.     \\r'.format(i))\n",
    "            if i > 5:\n",
    "                return loaded_files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = load_file_data(OUTPUT_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd['vid3/frameAnnotations-vid_cmp2.avi_annotations/stop_1323819291.avi_image14.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_iterator = tf.python_io.tf_record_iterator(path=OUTPUT_TEST)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    \n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example.features.feature['image/object/bbox/xmin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code, may be useful for creating an ampty pascal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXML(filename, folder = './img', imgsize = [640, 480, 3]):\n",
    "    tree = ET.parse(\"empty.xml\")\n",
    "    root = tree.getroot()\n",
    "    root.find('folder').text = folder\n",
    "    root.find('filename').text = filename\n",
    "    root.find('path').text = '{}/{}'.format(folder, filename)\n",
    "    \n",
    "    size = root.find('size')\n",
    "    size.find('width').text = str(imgsize[0])    \n",
    "    size.find('height').text = str(imgsize[1])    \n",
    "    size.find('depth').text = str(imgsize[2])    \n",
    "    \n",
    "    return tree\n",
    "annotation = createXML('myfile.jpg')\n",
    "ET.dump(annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = df.Filename.unique()\n",
    "for filename in files[:1]:\n",
    "    file = filename.split('/')[-1]\n",
    "    folder = '/'.join(filename.split('/')[:-1])\n",
    "    myXML = createXML(file, folder)\n",
    "    ET.dump(myXML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in root.findall('object'):\n",
    "    print (type(obj))\n",
    "    name = obj.find(\"name\").text\n",
    "    print (name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "def createXML(filename, folder = './img', imgsize = [640, 480, 3]):\n",
    "    # <annotation>\n",
    "    annot = ET.Element('annotation')\n",
    "    annot.set('version', '1.0')\n",
    "    #     <folder></folder>\n",
    "    fol = ET.SubElement(annot, 'folder')\n",
    "    fol.text = folder\n",
    "    #     <filename></filename>\n",
    "    fn = ET.SubElement(annot, 'filename')\n",
    "    fn.text = 'Filename'\n",
    "    #     <path></path>\n",
    "    path = ET.SubElement(annot, 'path')\n",
    "    path.text = folder+filename\n",
    "    #     <source>\n",
    "    #         <database></database>\n",
    "    #     </source>\n",
    "    source = ET.SubElement(annot, 'source')\n",
    "    database = ET.SubElement(source, 'database')\n",
    "    database.text = 'Unknown'\n",
    "    #     <size>\n",
    "    #         <width></width>\n",
    "    #         <height></height>\n",
    "    #         <depth></depth>\n",
    "    #     </size>\n",
    "    size = ET.SubElement(annot, 'size')\n",
    "    width = ET.SubElement(size, 'width')\n",
    "    height = ET.SubElement(size, 'height')\n",
    "    depth = ET.SubElement(size, 'depth')\n",
    "    width.text = '{}'.format(imgsize[0])\n",
    "    height.text = '{}'.format(imgsize[1])\n",
    "    depth.text = '{}'.format(imgsize[2])\n",
    "    #     <segmented></segmented>\n",
    "    segmented = ET.SubElement(annot, 'segmented')\n",
    "    segmented.text = '0'\n",
    "    return annot\n",
    "\n",
    "annotation = createXML('myfile.jpg')\n",
    "#ET.dump(annotation)\n",
    "print (prettify(annotation))\n",
    "#annotation.write('test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<annotation>\n",
    "     <folder></folder>\n",
    "     <filename></filename>\n",
    "     <path></path>\n",
    "     <source>\n",
    "         <database></database>\n",
    "     </source>\n",
    "     <size>\n",
    "         <width></width>\n",
    "         <height></height>\n",
    "         <depth></depth>\n",
    "     </size>\n",
    "     <segmented></segmented>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six.moves.urllib as urllib\n",
    "import tarfile\n",
    "import os \n",
    "# What model to download.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "opener = urllib.request.URLopener()\n",
    "opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "tar_file = tarfile.open(MODEL_FILE)\n",
    "for file in tar_file.getmembers():\n",
    "  file_name = os.path.basename(file.name)\n",
    "  if 'frozen_inference_graph.pb' in file_name:\n",
    "    tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
